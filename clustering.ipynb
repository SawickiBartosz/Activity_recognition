{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from itertools import combinations, permutations\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import entropy\n",
    "from scipy.special import kl_div\n",
    "from utils import get_data_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data_train()\n",
    "n_bins = 5 # tu możemy wybrać różną liczbę kuełków go generowania histogramów\n",
    "            # liczbę przedziałów na jakich będziemy liczyć dywergencję"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activities = np.unique(df['activity'])\n",
    "activities_dict = {activity: None for activity in activities}\n",
    "activities_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for activity in activities_dict.keys():\n",
    "    numerical_features = df[df['activity']==activity].drop(['activity', 'subject'], axis='columns')\n",
    "    activities_dict[activity] = numerical_features.apply(\n",
    "        lambda column: \n",
    "        np.histogram(column, bins=n_bins, density=True, range=(-1,1))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "combi_colnames = list(map('-'.join, list(permutations(activities,2))))\n",
    "combi_df = pd.DataFrame(columns = combi_colnames)\n",
    "\n",
    "numerical_features = df.drop(['activity', 'subject'], axis='columns').columns\n",
    "for feature in numerical_features:\n",
    "    combi_df = combi_df.append(pd.Series(np.repeat(feature, 30), name=feature, index=combi_colnames))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_inf_and_sum(feature1, feature2, x):\n",
    "    kl = kl_div(\n",
    "        activities_dict[feature1][x],\n",
    "        activities_dict[feature2][x])\n",
    "    return sum(map(lambda x: 100 if x>100 else x, kl))\n",
    "\n",
    "def count_inf(feature1, feature2, x):\n",
    "    return sum(\n",
    "        np.isinf(          # tu zliczamy infy\n",
    "            kl_div(\n",
    "                activities_dict[feature1][x],\n",
    "                activities_dict[feature2][x])))\n",
    "\n",
    "def take_median(feature1, feature2, x):\n",
    "    return np.median(          \n",
    "            kl_div(\n",
    "                activities_dict[feature1][x],\n",
    "                activities_dict[feature2][x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_column(column):\n",
    "    feature1, feature2 = column.name.split('-')\n",
    "    return column.apply(lambda x: replace_inf_and_sum(feature1, feature2, x)) # w tej lambdzie można wybrać inną funkcję\n",
    "\n",
    "\n",
    "result = combi_df.apply(apply_to_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_best = result.apply(lambda x: max(x), axis=1).sort_values(ascending=False).head(20).index.to_list()\n",
    "avg_best = result.apply(lambda x: sum(x), axis=1).sort_values(ascending=False).head(20).index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_var(varname):\n",
    "    sns.displot(df, x=varname, hue='activity', kind='kde')#bins=n_bins, multiple='dodge')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for varname in chosen_best: # lub alternatywnie chosen_best\n",
    "    plot_var(varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_with_categorical = chosen_best + ['activity', 'subject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chosen = pd.DataFrame( df[ best_with_categorical])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chosen_sep_by_act = []\n",
    "for i in range(6):\n",
    "    df_chosen_sep_by_act.append([])\n",
    "\n",
    "for i in range(6):\n",
    "    df_chosen_sep_by_act[i] = df_chosen[ df_chosen['activity'] == activities[i]].copy()\n",
    "    df_chosen_sep_by_act[i].drop( columns=['activity', 'subject'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "\n",
    "# Generujemy nowe dane o mnjejszej liczbie punktów (dla czytelności)\n",
    "Z = hierarchy.linkage( df_chosen_sep_by_act[0], method='average')\n",
    "plt.figure(figsize=(10, 5), dpi= 200, facecolor='w', edgecolor='k')\n",
    "hierarchy.dendrogram(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A w praktyce wygląda to tak:\n",
    "def count_clustering_scores(X, cluster_num, model, score_fun):\n",
    "    # Napiszmy tę funkcje tak ogólnie, jak to możliwe. \n",
    "    # Zwróćcie uwagę na przekazanie obiektów typu callable: model i score_fun.\n",
    "    if isinstance(cluster_num, int):\n",
    "        cluster_num_iter = [cluster_num]\n",
    "    else:\n",
    "        cluster_num_iter = cluster_num\n",
    "        \n",
    "    scores = []    \n",
    "    for k in cluster_num_iter:\n",
    "        model_instance = model(n_clusters=k)\n",
    "        labels = model_instance.fit_predict(X)\n",
    "        wcss = score_fun(X, labels)\n",
    "        scores.append(wcss)\n",
    "    \n",
    "    if isinstance(cluster_num, int):\n",
    "        return scores[0]\n",
    "    else:\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chosen_sep_by_act[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "silhouette_vec = []\n",
    "plots = []\n",
    "for i in range(6):\n",
    "    # In each iteration, add an empty list to the main list\n",
    "    silhouette_vec.append([])\n",
    "    plots.append([])\n",
    "\n",
    "cluster_num_seq = list( range(2, 11)) # Niektóre metryki nie działają gdy mamy tylko jeden klaster\n",
    "\n",
    "for i in range(6):\n",
    "    \n",
    "    silhouette_vec[i] = count_clustering_scores(\n",
    "        df_chosen_sep_by_act[i], cluster_num_seq, KMeans, silhouette_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in range(6):\n",
    "    # In each iteration, add an empty list to the main list\n",
    "    frames.append([])\n",
    "\n",
    "for i in range(6):\n",
    "    frames[i] = pd.DataFrame(\n",
    "        np.array(\n",
    "            [silhouette_vec[i], list( cluster_num_seq)]).transpose(),\n",
    "        columns = [\"silhouette\", \"no of clusters\"])\n",
    "    frames[i][\"acitivity\"] = activities[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = pd.concat( frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(rc={\"figure.figsize\":(12, 8)})\n",
    "sns.lineplot(data= stacked, \n",
    "             x=\"no of clusters\", y=\"silhouette\", hue=\"acitivity\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = np.unique( df[\"subject\"])\n",
    "n_subjects = len( subjects)\n",
    "df_by_subject = []\n",
    "clusters = []\n",
    "\n",
    "df_by_subject_by_cluster = []\n",
    "\n",
    "for i in range( n_subjects):\n",
    "    # In each iteration, add an empty list to the main list\n",
    "    df_by_subject.append([])\n",
    "    clusters.append([])\n",
    "    df_by_subject_by_cluster.append([])\n",
    "    \n",
    "    for j in range( 6):\n",
    "        df_by_subject_by_cluster[i].append([])\n",
    "\n",
    "for i in range( n_subjects):\n",
    "    df_by_subject[i] = df[df[\"subject\"] == subjects[i]].copy()\n",
    "    df_by_subject[i].drop( columns=['activity', 'subject'], inplace = True)\n",
    "    \n",
    "    clusters[i] = KMeans(n_clusters=6, random_state=1618).fit( df_by_subject[i])\n",
    "    df_by_subject[i][\"cluster\"] = clusters[i].labels_\n",
    "    \n",
    "    for j in range( 6):\n",
    "        df_by_subject_by_cluster[i][j] = df_by_subject[i][ df_by_subject[i][\"cluster\"] == j ].copy()\n",
    "        df_by_subject_by_cluster[i][j].drop( columns = [\"cluster\"], inplace = True)\n",
    "        df_by_subject_by_cluster[i][j] = df_by_subject_by_cluster[i][j].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters[0].cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import statistics\n",
    "\n",
    "distances = []\n",
    "\n",
    "for i in range( n_subjects):\n",
    "    # In each iteration, add an empty list to the main list\n",
    "    distances.append([])\n",
    "\n",
    "    for j in range( n_subjects):\n",
    "        distances[i].append([])\n",
    "\n",
    "\n",
    "for i in range( n_subjects):\n",
    "    for j in range( n_subjects):\n",
    "        \n",
    "        dists_to_clusters = []\n",
    "        for k in range(6):\n",
    "            dists_to_clusters.append([])\n",
    "            \n",
    "            dist_from_single = []\n",
    "            for l in range(6):\n",
    "                dist_from_single.append([])\n",
    "                dist_from_single[l] = distance.euclidean(\n",
    "                    clusters[i].cluster_centers_[k], clusters[j].cluster_centers_[l]\n",
    "                )\n",
    "            dists_to_clusters[k] = min( dist_from_single)\n",
    "        distances[i][j] =  statistics.mean( dists_to_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import statistics\n",
    "\n",
    "distances2 = []\n",
    "\n",
    "for i in range( n_subjects):\n",
    "    # In each iteration, add an empty list to the main list\n",
    "    distances2.append([])\n",
    "\n",
    "    for j in range( n_subjects):\n",
    "        distances2[i].append([])\n",
    "\n",
    "\n",
    "for i in range( n_subjects):\n",
    "    for j in range( n_subjects):\n",
    "        \n",
    "        dists_to_clusters = []\n",
    "        for k in range(6):\n",
    "            dists_to_clusters.append([])\n",
    "            \n",
    "            dist_from_single = []\n",
    "            for l in range(6):\n",
    "                dist_from_single.append([])\n",
    "                dist_from_single[l] = distance.euclidean(\n",
    "                    clusters[i].cluster_centers_[k], clusters[j].cluster_centers_[l]\n",
    "                )\n",
    "            dists_to_clusters[k] = min( dist_from_single)\n",
    "        distances2[i][j] =  max( dists_to_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap( distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap( distances2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "cluster_num_seq = [x for x in range(2, 11)]\n",
    "silhouette_vec = count_clustering_scores(df.drop(columns=['subject', 'activity']), cluster_num_seq, KMeans, silhouette_score)\n",
    "plt.plot(cluster_num_seq, silhouette_vec, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.title('Clustering on a full data set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_vec_chosen = count_clustering_scores(df[chosen_best], cluster_num_seq, KMeans, silhouette_score)\n",
    "plt.plot(cluster_num_seq, silhouette_vec, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.title('Clustering on chosen best columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_vec_avg_best = count_clustering_scores(df[avg_best], cluster_num_seq, KMeans, silhouette_score)\n",
    "plt.plot(cluster_num_seq, silhouette_vec, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.title('Clustering on avarage best columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(\n",
    "    {'Full dataset': silhouette_vec, \n",
    "     '20 best chosen columns': silhouette_vec_chosen, \n",
    "     '20 best in average columns': silhouette_vec_avg_best})\n",
    "display(tmp)\n",
    "tmp = pd.concat([tmp,pd.Series(cluster_num_seq, name='k')], axis=1, join='inner', ignore_index=True)\n",
    "tmp.columns = ['Full dataset', '20 best chosen columns', '20 best in average columns', 'k']\n",
    "tmp.plot(x='k', style=['r-.', 'b-', 'g--'], title='K-Means clustering', ylabel='Silhuette score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import (\n",
    "    SilhouetteVisualizer,\n",
    "    KElbowVisualizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "km = KMeans(random_state=123)\n",
    "visualizer = KElbowVisualizer(km, k=(2,10))\n",
    "visualizer.fit(df.drop(columns=['subject', 'activity']))\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = KElbowVisualizer(km, k=(2,10))\n",
    "visualizer.fit(df[avg_best])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualizer = KElbowVisualizer(km, k=(2,10))\n",
    "visualizer.fit(df[chosen_best])\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_cols_clusterer = KMeans(random_state=123, n_clusters=4)\n",
    "all_cols_clusterer.fit(df.drop(columns=['subject', 'activity']))\n",
    "visualizer = silhouette_visualizer(all_cols_clusterer,\n",
    "                                    X=df.drop(columns=['subject', 'activity']), \n",
    "                                    colors='yellowbrick',\n",
    "                                    is_fitted=True)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(15,12), sharex=True)\n",
    "\n",
    "km = KMeans(n_clusters=4, max_iter=100, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[0])\n",
    "visualizer.fit(df.drop(columns=['subject', 'activity']))\n",
    "visualizer.finalize()\n",
    "ax[0].set_title('Full dataset')\n",
    "\n",
    "\n",
    "\n",
    "km = KMeans(n_clusters=4, max_iter=100, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[1])\n",
    "visualizer.fit(df[chosen_best])\n",
    "visualizer.finalize()\n",
    "ax[1].set_title('20 best chosen columns')\n",
    "\n",
    "\n",
    "\n",
    "km = KMeans(n_clusters=4, max_iter=100, random_state=42)\n",
    "visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[2])\n",
    "visualizer.fit(df[avg_best])\n",
    "visualizer.finalize()\n",
    "ax[2].set_title('20 best in average columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "cluster_num_seq = [x for x in range(2, 11)]\n",
    "silhouette_vec = count_clustering_scores(df.drop(columns=['subject', 'activity']),\n",
    "                                         cluster_num_seq, AgglomerativeClustering, \n",
    "                                         silhouette_score)\n",
    "\n",
    "plt.plot(cluster_num_seq, silhouette_vec, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.title('Agglomerative Clustering on full dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "silhouette_vec_best = count_clustering_scores(df[avg_best],\n",
    "                                         cluster_num_seq, AgglomerativeClustering, \n",
    "                                         silhouette_score)\n",
    "\n",
    "plt.plot(cluster_num_seq, silhouette_vec_best, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.title('Agglomerative Clustering on full dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5, 2, figsize=(25,24), sharex=True)\n",
    "for i in range(2,12):\n",
    "    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "    q, mod = divmod(i, 2)\n",
    "\n",
    "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(df[chosen_best])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
